data_dir: data
exp_dir: exp

anon_data_suffix: _mcadams # added to transform data/libri_dev/ to data/libri_dev_mcadams/ with data/libri_dev_mcadams/wav/*wav

results_summary_path: !ref <exp_dir>/results_summary/eval_orig<anon_data_suffix>/results_orig.txt

datasets:
  - name: cn_test
    data: cn_test
    enrolls: [_enrolls]
    trials: [_trials_f, _trials_m]
  

eval_steps:  # all metrics in this list will be computed in the evaluation. Remove entry to skip
#privacy:
#   - asv
  utility:
    - asr

privacy:
  asv:
    dataset_name: [cn_test]
    model_name: asv_ssl
    model_type: sslecapa

    evaluation:
      model_dir: !ref <exp_dir>/<privacy[asv][model_name]>  # path to existing ASV model or output for trained ASV model
      results_dir: !ref <exp_dir>/<privacy[asv][model_name]>  # path to save evaluation results
      distance: cosine  # cosine or plda
      plda:   # ignored if distance is not plda
        model_dir: null  # path to trained PLDA or output of PLDA training
        train_data_dir: null # path to PLDA training data
        anon: null # trained on anonymized (true) or original (false) data

utility:
  asr:
    dataset_name: [cn_test, mls_german_test, mls_italian_test, mls_french_test, mls_polish_test, mls_portuguese_test, mls_spanish_test,mls_dutch_test]

    model_name: openai/whisper-large-v3 # name for ASR model, asr_pre_transformer_transformerlm + EncoderDecoderASR or asr_pre_ctc_wav2vec2 + EncoderASR

    evaluation:
      model_type: whisper # EncoderDecoderASR or EncoderASR (from speechbrain)
      backend: whisper
      # hparams_file: hyperparams.yaml # Check the 'model_dir' config yaml file, default to 'hyperparams.yaml'
      model_dir: !ref <exp_dir>/<utility[asr][model_name]>
      eval_batchsize: 8 # Requires < 12Gib for the 'asr_pre_ctc_wav2vec2' model
      results_dir: !ref <exp_dir>/<utility[asr][model_name]>
